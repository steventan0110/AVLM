# [Seeing is Believing: Emotion-Aware Audio-Visual Language Modeling for Expressive Speech Generation](https://www.arxiv.org/abs/2508.16188)
**Weiting Tan, Jiachen Lian, Hirofumi Inaguma, Paden Tomasello, Philipp Koehn, Xutai Ma**

<p align="center">
<a href="LICENSE" alt="MIT License"><img src="https://img.shields.io/badge/license-MIT-FAD689.svg" /></a>
<a href="https://www.arxiv.org/abs/2508.16188" alt="paper"><img src="https://img.shields.io/badge/AVLM-Paper-D9AB42" /></a>
<a href="https://www.clsp.jhu.edu/" alt="jhu"><img src="https://img.shields.io/badge/Johns_Hopkins_University-BEC23F" /></a>
<a href="https://twitter.com/weiting_nlp">
  <img src="https://img.shields.io/twitter/follow/weiting_nlp?style=social&logo=twitter"
      alt="follow on Twitter"></a>
</p>

---

**AVLM** is a research project that targets modality fusion, integrating visual and speech representation into pre-trained SpeechLM for expressive generation.


## ðŸ”§ Project Structure

```bash
AVLM/
â”œâ”€â”€ scripts/  # main scripts
â”‚   â”œâ”€â”€ avlm/ # folder for AVLM pretraining (with different fusion strategies)
â”‚   â”œâ”€â”€ avlm_avsr/ # folder for fine-tuning AVLM to perform AVSR task
â”‚   â”œâ”€â”€ avlm_emo/ # folder for fine-tuning AVLM for expressive speech generation
â”‚   â”œâ”€â”€ global.sh # config script for paths
â”œâ”€â”€ src/                     # Core source code
â”‚   â”œâ”€â”€ data_utils/          # Data loading and preprocessing
â”‚   â”œâ”€â”€ models/              # Customized SpiritLM model 
â”‚   â”œâ”€â”€ exp/                 # spiritlm source code
â”‚   â”œâ”€â”€ preprocess/          # video data preprocessing
â”‚   â”œâ”€â”€ task/          # lighting trainer files
â”‚   â”œâ”€â”€â”œâ”€â”€ avlm_iemocap_tune.py # fine-tune AVLM for expressive dialogue generation
â”‚   â”œâ”€â”€â”œâ”€â”€ train_avlm.py # pre-train AVLM with differenet fusion strategies or fine-tune AVLM for AVSR task
```

---



### If you find our work useful, please cite:
```
@misc{tan2025seeingbelievingemotionawareaudiovisual,
      title={Seeing is Believing: Emotion-Aware Audio-Visual Language Modeling for Expressive Speech Generation}, 
      author={Weiting Tan and Jiachen Lian and Hirofumi Inaguma and Paden Tomasello and Philipp Koehn and Xutai Ma},
      year={2025},
      eprint={2508.16188},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2508.16188}, 
}
```
